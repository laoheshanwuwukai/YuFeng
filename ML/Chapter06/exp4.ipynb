{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp4: 基于K-近邻的车牌号识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、案例简介\n",
    "\n",
    "图像的智能处理一直是人工智能领域广受关注的一类技术，代表性的如人脸识别与 CT 肿瘤识别，在人工智能落地的进程中发挥着重要作用。其中车牌号识别作为一个早期应用场景，已经融入日常生活中，为我们提供了诸多便利，在各地的停车场和出入口都能看到它的身影。车牌号识别往往分为字符划分和字符识别两个子任务，本案例我们将关注字符识别的任务，尝试用 K-NN 的方法对分割好的字符图像进行自动识别和转化。\n",
    "\n",
    "## 二、作业说明\n",
    "\n",
    "### 基本要求\n",
    "* 完成数据的读入和表示，将图片表示成向量并和 label 对应上；\n",
    "* 构建 K-NN 模型（可调库）对测试集中的图片进行预测并计算准确率；\n",
    "* 分析当 K 取不同值时测试准确率的变化。\n",
    "\n",
    "### 扩展要求\n",
    "* 分析不同距离度量方式对模型效果的影响；\n",
    "* 对比平权和加权 K-NN 的效果；\n",
    "* 分析训练集大小对测试结果的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据概览\n",
    "本次我们使用已经分割好的车牌图片作为数据集，包括数字 0-9、字母 A-Z（不包含 O 和 I）以及省份简称共 65 个类，编号从 0 到 64。数据已经分成了训练集和测试集，里面的文件夹用 label 编号命名，一个文件夹下的所有图片都属于该文件夹对应的类，每个图片都是 20 * 20 的二值化灰度图。\n",
    "\n",
    "下面演示一下如何借助 PIL 库将图片转化为向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List,Dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAUABQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APOPg/Zw33xW0CGddyLK8wGAfmjjd1PP+0orvNL8Yal8R/BXxAh1/wAqW2tLX7XZxKgU27AuygMACQNqjJ5IHua8Kr0D4Jf8le0L/t4/9J5K1vharf8ACFfEhsHaNJwTjjO2WvKa3/BWrXOh+NdI1C02+dHcqo3ZwQ3ykHBHZjXvvxh0+y8H/DjUjoFrHYPrOoIt9JFkPKG3MRnOQMjG3phmGOTXzHX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAAAAACo4kLRAAAA6ElEQVR4AT2QMU5EMQxEx06iz0rcADpOQEG9NZeiXaqVkLgAJ4FzgLjGCv0kHhzn73cT5WU89gRAgkJtpTWekREljuSVvPyR1EAKJohrcf/wTH6kKQzC9rYgf7afKRWBiLDeQvTLvmc76Za0LJLNfWRQdaVZRgVrYe8BM5G6NFU/K5JaKIEePn7zh2Bjl1lFuyXzJF47rILiLtG2QxDV2+f0rRvJIy7Ypl8hPe4F5Tp9YkGTpU633dPD3DyVtiWKBTpOPukwVh2VR1w99/XuSPNYwZp/R16r6u9i+r7Fi++EvrBVtkcJ5T9telz1aQmh0QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=20x20>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = Image.open('data/train/0/4-3.jpg')  # 打开图片\n",
    "pixels = np.array(img)  # 转化为 numpy 矩阵\n",
    "print(pixels.shape)\n",
    "img  # 显示图片from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for load train and test datas\n",
    "def GlobFolder(folder:Path):\n",
    "    subfolders = []\n",
    "    for sub in folder.iterdir():\n",
    "        if sub.is_dir():\n",
    "            subfolders.append(sub)\n",
    "    return subfolders\n",
    "\n",
    "def GlobJPGFile(folder:Path):\n",
    "    return list(folder.glob(\"*.jpg\"))\n",
    "\n",
    "def LoadLableAndDatas(root:Path):\n",
    "    # input : std::filesystem::path . means folder contain\n",
    "    # output: std::map<int , cv::Mat>\n",
    "    lable_imgs = {}\n",
    "    total_sub_folder:List[Path] = GlobFolder(root)\n",
    "    for each_folder in total_sub_folder:\n",
    "        total_img_file = GlobJPGFile(each_folder)\n",
    "        lable = int(each_folder.stem)\n",
    "        lable_imgs[lable]=[]\n",
    "        for each_jpg_file in total_img_file:\n",
    "            img = Image.open(each_jpg_file.as_posix())\n",
    "            # Important: Normalize grayscale values to the [0, 1] range\n",
    "            pixels = np.array(img, dtype=np.float32)\n",
    "            pixels /= 255\n",
    "            pixels = pixels.flatten()\n",
    "            lable_imgs[lable].append(pixels)\n",
    "    return lable_imgs\n",
    "\n",
    "def SeparateLableAndDatas(data):\n",
    "    # input: std::map<int , std::vector<cv::Mat> >  // means lable and vector of img array\n",
    "    # output: std::vector<int> , std::vector<cv::Mat> // vector of lable and vector of img array\n",
    "    lables = []\n",
    "    datas  = []\n",
    "    for lable , total_array in data.items():\n",
    "        for array in total_array:\n",
    "            lables.append(lable)\n",
    "            datas.append(array)\n",
    "    return lables, datas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train/test lable size 65 / 65\n",
      "Load train/test data  size 15954 / 4665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datas\n",
    "cwd = Path.cwd()\n",
    "train_folder = cwd/('data/train')\n",
    "test_folder = cwd/('data/test')\n",
    "if not train_folder.exists() or not test_folder.exists():\n",
    "    print(f\"Error with load datas {train_folder.as_posix()} , {test_folder.as_posix()}\")\n",
    "    exit(1)\n",
    "# datas type std::map<int , std::vector<cv::Mat> >\n",
    "train_lable_imgs = LoadLableAndDatas(train_folder)\n",
    "test_lable_imgs = LoadLableAndDatas(test_folder)\n",
    "\n",
    "train_lables, train_arrays = SeparateLableAndDatas(train_lable_imgs)\n",
    "test_lables , test_arrays = SeparateLableAndDatas(test_lable_imgs)\n",
    "assert( len(train_lables)== len(train_arrays) and len(test_lables) == len(test_arrays))\n",
    "print(f\"Load train/test lable size {len(train_lable_imgs)} / {len(test_lable_imgs)}\")\n",
    "print(f\"Load train/test data  size {len(train_arrays)} / {len(test_arrays)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型构建\n",
    "已经读取 归一化后 的 向量格式数据\n",
    "\n",
    "- train_lables: 训练集标签 \n",
    "- train_arrays: 训练集数据\n",
    "- test_lables : 测试集标签\n",
    "- test_arrays : 测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best params: {'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "Best acc: 0.7168274383708467\n"
     ]
    }
   ],
   "source": [
    "# 尝试一下GridSearchCV,上次作业没用上\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'], # 距离计算方法，uniform 等权重，distance 根据距离设置权重投票\n",
    "    'p': [1, 2]                         # 距离度量：1=曼哈顿，2=欧氏\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(), \n",
    "    param_grid, \n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    cv=5)\n",
    "\n",
    "grid_search.fit(train_arrays, train_lables)\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best acc: {best_model.score(test_arrays, test_lables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using (K =1 with uniform  weights and Manhattan distance). Accuracy socre: 0.7142550911039657\n",
      " Using (K =1 with uniform  weights and Euclidean distance). Accuracy socre: 0.7168274383708467\n",
      " Using (K =1 with distance weights and Manhattan distance). Accuracy socre: 0.7142550911039657\n",
      " Using (K =1 with distance weights and Euclidean distance). Accuracy socre: 0.7168274383708467\n",
      "\n",
      " Using (K =3 with uniform  weights and Manhattan distance). Accuracy socre: 0.6906752411575563\n",
      " Using (K =3 with uniform  weights and Euclidean distance). Accuracy socre: 0.69989281886388\n",
      " Using (K =3 with distance weights and Manhattan distance). Accuracy socre: 0.7061093247588425\n",
      " Using (K =3 with distance weights and Euclidean distance). Accuracy socre: 0.7103965702036441\n",
      "\n",
      " Using (K =5 with uniform  weights and Manhattan distance). Accuracy socre: 0.6827438370846731\n",
      " Using (K =5 with uniform  weights and Euclidean distance). Accuracy socre: 0.6928188638799572\n",
      " Using (K =5 with distance weights and Manhattan distance). Accuracy socre: 0.697534833869239\n",
      " Using (K =5 with distance weights and Euclidean distance). Accuracy socre: 0.7016077170418007\n",
      "\n",
      " Using (K =7 with uniform  weights and Manhattan distance). Accuracy socre: 0.6801714898177921\n",
      " Using (K =7 with uniform  weights and Euclidean distance). Accuracy socre: 0.692390139335477\n",
      " Using (K =7 with distance weights and Manhattan distance). Accuracy socre: 0.6891747052518756\n",
      " Using (K =7 with distance weights and Euclidean distance). Accuracy socre: 0.6992497320471597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlist = [1,3,5,7]\n",
    "wlist = ['uniform','distance']\n",
    "plist = [1,2]\n",
    "for n in nlist:\n",
    "    for w in wlist:\n",
    "        for p in plist:\n",
    "            knn = KNeighborsClassifier(\n",
    "                n_neighbors=n,\n",
    "                weights= w,         # uniform , distance\n",
    "                algorithm='auto',   # auto , ball_tree , kd_tree , brute\n",
    "                p=p,                # p=2 \n",
    "                n_jobs=-1           # for cpu core\n",
    "                )\n",
    "            knn.fit(train_arrays , train_lables)\n",
    "\n",
    "            lable_pred = knn.predict(test_arrays)\n",
    "            accuracy = accuracy_score(lable_pred , test_lables)\n",
    "            print(f\" Using (K ={n} with {\"uniform \" if w == 'uniform' else 'distance'} weights and {\"Euclidean\" if p==2 else \"Manhattan\"} distance). Accuracy socre: {accuracy}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "**基本要求**： \n",
    "- 数据读取中 将标签设置为文件夹名称，图片已经归一化并转换成向量，两者一一对应。\n",
    "- 构建KNN模型，计算准确率 max:0.7168274383708467。 \n",
    "- 尝试了K分别取1,3,5,7,9,发现在K=1时 准确率最高，也就是之用一个邻居来投票效果最好，同时还发现在k=1时，等权重和带权重的方法准确率一样，这个结论也复合预期，因为只有1个邻居投票，占了全部的权重。当k依次曾大时，准确率降低，说明训练出来的模型中某些特征取值的附近空间中存在其他类别的特征，也就是不同标签的邻居干扰了投票结果。\n",
    "**扩展要求**：\n",
    "- 根据不同参数对比，发现使用Euclidean距离 的准确率 要优于Manhattan距离。借助GPT：欧式距离（Euclidean）往往比曼哈顿距离（Manhattan）效果更好，这是因为它更能捕捉图像的整体几何形状差异。而曼哈顿距离是 L1 范数，对所有像素差异一视同仁（线性相加）。它更适合用于稀疏、高维、非结构化数据（如词袋模型、推荐系统），而不是具有空间结构的图像。\n",
    "- 根据不同参数对比，发现加权要比平权准确率更高，这说明 在本次任务中 加权的权重策略使得 分类边界和抗干扰能力更好。\n",
    "**未实现**：\n",
    "分析训练集大小对测试结果的影响"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
